# ABLE Environment Configuration
# Copy this file to .env and fill in your values

# ============================================
# LLM API Configuration
# ============================================

# OpenAI API Key (required if using GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (required if using Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Default LLM Model
ABLE_LLM_MODEL=gpt-4.1-mini

# ============================================
# Path Configuration
# ============================================

# Output directory for build results
REPO2RUN_OUTPUT_ROOT=./output

# Log directory
ABLE_LOG_DIR=./build_agent/log

# ============================================
# Build Configuration
# ============================================

# Maximum turns for LLM agent
ABLE_MAX_TURN=100

# Command timeout (seconds)
ABLE_TIMEOUT=14400

# Docker image for C/C++ builds
ABLE_DOCKER_IMAGE=gcr.io/oss-fuzz-base/base-builder

# Container memory limit
ABLE_MEMORY_LIMIT=30g

# Container CPU limit
ABLE_CPU_LIMIT=0-15

# ============================================
# Feature Flags
# ============================================

# Enable Command Pattern (experimental)
ABLE_USE_COMMAND_PATTERN=false

# Enable verbose logging
ABLE_VERBOSE=false

# Enable debug mode
ABLE_DEBUG=false
